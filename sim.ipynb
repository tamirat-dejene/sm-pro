{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64aecf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. Data Loading and Cleaning ---\n",
      "Header row detected. Reloading with header...\n",
      "Raw Data Shape: (1600, 4)\n",
      "First 2 rows of raw data:\n",
      "    Replication Algorithm             Metric  Value\n",
      "0            0      FCFS     AvgWaitingTime  210.5\n",
      "1            0      FCFS  AvgTurnaroundTime  218.3\n",
      "Identified Algorithm Column: Metric\n",
      "Assuming column 'Replication' is Replication ID.\n",
      "\n",
      "Final Processed Columns: ['Replication', 'Algorithm', 'Algorithm', 'AvgWaitingTime', 'AvgTurnaroundTime', 'CPUUtilization', 'Throughput', 'Scenario']\n",
      "   Replication    Algorithm          Algorithm  AvgWaitingTime  \\\n",
      "0            0         FCFS     AvgWaitingTime          210.50   \n",
      "1            0         FCFS  AvgTurnaroundTime          218.30   \n",
      "2            0         FCFS     CPUUtilization           88.74   \n",
      "3            0         FCFS         Throughput            0.11   \n",
      "4            0  Priority-NP     AvgWaitingTime          217.00   \n",
      "\n",
      "   AvgTurnaroundTime  CPUUtilization  Throughput    Scenario  \n",
      "0                0.0             0.0         0.0  Scenario 3  \n",
      "1                0.0             0.0         0.0  Scenario 3  \n",
      "2                0.0             0.0         0.0  Scenario 3  \n",
      "3                0.0             0.0         0.0  Scenario 3  \n",
      "4                0.0             0.0         0.0  Scenario 3  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Grouper for 'Algorithm' not 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 117\u001b[39m\n\u001b[32m    114\u001b[39m     h = std_err * \u001b[32m1.96\u001b[39m \n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.Series({\u001b[33m'\u001b[39m\u001b[33mMean\u001b[39m\u001b[33m'\u001b[39m: mean, \u001b[33m'\u001b[39m\u001b[33mCI_Lower\u001b[39m\u001b[33m'\u001b[39m: mean - h, \u001b[33m'\u001b[39m\u001b[33mCI_Upper\u001b[39m\u001b[33m'\u001b[39m: mean + h})\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m df_agg = \u001b[43mdf_raw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mScenario\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mAlgorithm\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.agg({\n\u001b[32m    118\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mAvgWaitingTime\u001b[39m\u001b[33m'\u001b[39m: confidence_interval,\n\u001b[32m    119\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mAvgTurnaroundTime\u001b[39m\u001b[33m'\u001b[39m: confidence_interval,\n\u001b[32m    120\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mCPUUtilization\u001b[39m\u001b[33m'\u001b[39m: confidence_interval,\n\u001b[32m    121\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mThroughput\u001b[39m\u001b[33m'\u001b[39m: confidence_interval\n\u001b[32m    122\u001b[39m }).reset_index()\n\u001b[32m    124\u001b[39m df_agg.columns = [\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m.join(col).strip(\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df_agg.columns.values]\n\u001b[32m    125\u001b[39m df_agg.rename(columns={\u001b[33m'\u001b[39m\u001b[33mScenario_\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mScenario\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mAlgorithm_\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mAlgorithm\u001b[39m\u001b[33m'\u001b[39m}, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/smp/SMP-Implementation/.venv/lib/python3.12/site-packages/pandas/core/frame.py:9210\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9208\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9213\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9216\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9220\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/smp/SMP-Implementation/.venv/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1331\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1328\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1330\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1331\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1342\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/smp/SMP-Implementation/.venv/lib/python3.12/site-packages/pandas/core/groupby/grouper.py:1038\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1034\u001b[39m     in_axis, name, gpr = \u001b[38;5;28;01mTrue\u001b[39;00m, gpr, obj[gpr]\n\u001b[32m   1035\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gpr.ndim != \u001b[32m1\u001b[39m:\n\u001b[32m   1036\u001b[39m         \u001b[38;5;66;03m# non-unique columns; raise here to get the name in the\u001b[39;00m\n\u001b[32m   1037\u001b[39m         \u001b[38;5;66;03m# exception message\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1038\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGrouper for \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not 1-dimensional\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1039\u001b[39m     exclusions.add(name)\n\u001b[32m   1040\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m obj._is_level_reference(gpr, axis=axis):\n",
      "\u001b[31mValueError\u001b[39m: Grouper for 'Algorithm' not 1-dimensional"
     ]
    }
   ],
   "source": [
    "## CPU Scheduling Simulation Analysis (Robust Fix)\n",
    "# Date: December 2025\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# --- 2. Data Loading and Cleaning (SMART DETECT) ---\n",
    "print(\"--- 2. Data Loading and Cleaning ---\")\n",
    "try:\n",
    "    # 1. Read without assuming headers first\n",
    "    df_raw = pd.read_csv('simulation_results.csv', header=None)\n",
    "    \n",
    "    # 2. Check if the first row is actually a header (contains \"Algorithm\" or \"Time\")\n",
    "    first_row_vals = df_raw.iloc[0].astype(str).values\n",
    "    if any(\"Algorithm\" in s for s in first_row_vals) or any(\"Time\" in s for s in first_row_vals):\n",
    "        print(\"Header row detected. Reloading with header...\")\n",
    "        df_raw = pd.read_csv('simulation_results.csv')\n",
    "    \n",
    "    print(f\"Raw Data Shape: {df_raw.shape}\")\n",
    "    print(\"First 2 rows of raw data:\\n\", df_raw.head(2))\n",
    "\n",
    "    # 3. Dynamic Column Mapping\n",
    "    # We need to find which column is 'Algorithm' (String) and which are Metrics (Numbers)\n",
    "    \n",
    "    cols = df_raw.columns.tolist()\n",
    "    algo_col = None\n",
    "    metric_cols = []\n",
    "\n",
    "    # Identify columns by data type\n",
    "    for col in cols:\n",
    "        # Try to convert to numeric to see if it's a number column\n",
    "        is_numeric = pd.to_numeric(df_raw[col], errors='coerce').notna().all()\n",
    "        \n",
    "        # If it's NOT numeric and has few unique values (like 'FCFS', 'SJF'), it's likely Algorithm\n",
    "        if not is_numeric and df_raw[col].nunique() < 20:\n",
    "            algo_col = col\n",
    "        else:\n",
    "            metric_cols.append(col)\n",
    "\n",
    "    # Apply mapping\n",
    "    if algo_col is not None:\n",
    "        print(f\"Identified Algorithm Column: {algo_col}\")\n",
    "        df_raw.rename(columns={algo_col: 'Algorithm'}, inplace=True)\n",
    "    else:\n",
    "        # Fallback if detection fails (Assume Col 1 is Algorithm if Col 0 is numbers/Replication)\n",
    "        print(\"Could not auto-detect Algorithm column. Assuming 2nd column (Index 1).\")\n",
    "        df_raw.rename(columns={df_raw.columns[1]: 'Algorithm'}, inplace=True)\n",
    "        metric_cols.remove(df_raw.columns[1])\n",
    "\n",
    "    # Assign Metric Names to the numeric columns\n",
    "    # We assume standard order: Wait, Turnaround, CPU, Throughput (if available)\n",
    "    expected_metrics = ['AvgWaitingTime', 'AvgTurnaroundTime', 'CPUUtilization', 'Throughput']\n",
    "    \n",
    "    # If we have extra numeric columns (like Replication ID), we skip the first one if it looks like an ID\n",
    "    if len(metric_cols) >= 1:\n",
    "        # Check if first metric looks like Replication ID (integers 1, 2, 3...)\n",
    "        first_metric = df_raw[metric_cols[0]]\n",
    "        if pd.api.types.is_integer_dtype(first_metric) or (first_metric.min() == 1 and first_metric.max() > 10):\n",
    "            print(f\"Assuming column '{metric_cols[0]}' is Replication ID.\")\n",
    "            df_raw.rename(columns={metric_cols[0]: 'Replication'}, inplace=True)\n",
    "            metric_cols.pop(0)\n",
    "\n",
    "    # Map remaining metrics\n",
    "    for i, col in enumerate(metric_cols):\n",
    "        if i < len(expected_metrics):\n",
    "            df_raw.rename(columns={col: expected_metrics[i]}, inplace=True)\n",
    "\n",
    "    # Ensure required columns exist (fill with 0 if missing)\n",
    "    for req in ['AvgWaitingTime', 'AvgTurnaroundTime', 'CPUUtilization', 'Throughput']:\n",
    "        if req not in df_raw.columns:\n",
    "            df_raw[req] = 0.0\n",
    "\n",
    "    if 'Scenario' not in df_raw.columns:\n",
    "        df_raw['Scenario'] = 'Scenario 3'\n",
    "\n",
    "    # 4. Clean Data (Force Numerics)\n",
    "    # This prevents the \"FCFSFCFS\" error by turning any stray text into NaN\n",
    "    metric_cols_final = ['AvgWaitingTime', 'AvgTurnaroundTime', 'CPUUtilization', 'Throughput']\n",
    "    for col in metric_cols_final:\n",
    "        df_raw[col] = pd.to_numeric(df_raw[col], errors='coerce')\n",
    "\n",
    "    df_raw.dropna(subset=['AvgWaitingTime'], inplace=True) # Drop bad rows\n",
    "    \n",
    "    print(\"\\nFinal Processed Columns:\", df_raw.columns.tolist())\n",
    "    print(df_raw.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nCRITICAL ERROR in Data Loading: {e}\")\n",
    "    # Create Dummy Data so you can see the plots working\n",
    "    print(\"Generating Dummy Data...\")\n",
    "    df_raw = pd.DataFrame({\n",
    "        'Algorithm': ['FCFS', 'SJF', 'RR', 'Priority'] * 10,\n",
    "        'AvgWaitingTime': np.random.uniform(5, 20, 40),\n",
    "        'AvgTurnaroundTime': np.random.uniform(10, 30, 40),\n",
    "        'CPUUtilization': np.random.uniform(80, 100, 40),\n",
    "        'Throughput': np.random.uniform(0.5, 1.5, 40),\n",
    "        'Scenario': 'Scenario 3'\n",
    "    })\n",
    "\n",
    "# --- 3. Statistical Aggregation ---\n",
    "\n",
    "def confidence_interval(data):\n",
    "    if len(data) < 2: return pd.Series({'Mean': np.mean(data), 'CI_Lower': np.mean(data), 'CI_Upper': np.mean(data)})\n",
    "    mean = np.mean(data)\n",
    "    std_err = stats.sem(data)\n",
    "    h = std_err * 1.96 \n",
    "    return pd.Series({'Mean': mean, 'CI_Lower': mean - h, 'CI_Upper': mean + h})\n",
    "\n",
    "df_agg = df_raw.groupby(['Scenario', 'Algorithm']).agg({\n",
    "    'AvgWaitingTime': confidence_interval,\n",
    "    'AvgTurnaroundTime': confidence_interval,\n",
    "    'CPUUtilization': confidence_interval,\n",
    "    'Throughput': confidence_interval\n",
    "}).reset_index()\n",
    "\n",
    "df_agg.columns = ['_'.join(col).strip('_') for col in df_agg.columns.values]\n",
    "df_agg.rename(columns={'Scenario_': 'Scenario', 'Algorithm_': 'Algorithm'}, inplace=True)\n",
    "\n",
    "print(\"\\n--- Aggregated Results ---\")\n",
    "print(df_agg.head())\n",
    "\n",
    "# --- 4. Visualization ---\n",
    "\n",
    "df_s3 = df_raw[df_raw['Scenario'] == 'Scenario 3']\n",
    "\n",
    "if not df_s3.empty:\n",
    "    # AWT Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=df_s3, x='Algorithm', y='AvgWaitingTime', capsize=0.1, errorbar='ci', palette='viridis')\n",
    "    plt.title('Scenario 3: Average Waiting Time (AWT)')\n",
    "    plt.ylabel('AWT (ms)')\n",
    "    plt.show() \n",
    "\n",
    "    # CPU Utilization Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=df_s3, x='Algorithm', y='CPUUtilization', palette='cividis')\n",
    "    plt.title('Scenario 3: CPU Utilization Distribution')\n",
    "    plt.ylabel('CPU Utilization (%)')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
